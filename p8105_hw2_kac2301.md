p8105_hw2_kac2301
================
Kate Colvin

## Problem 1

``` r
# Reading in and cleaning NYC subway data

nyc_df <- read_csv("Data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(entry = 
           case_match(
             entry, 
             "YES" ~ TRUE,
             "NO" ~ FALSE 
           ))
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

These data describe the entrances and exits to all of the NYC subway
stations. To clean this data, I renamed the columns using clean_names(),
kept only important columns outlined by the assignment, and converted
the “entry” variable values to TRUE/FALSE. There are 1868 rows
(entrances or exits) and 32 columns (variables). I don’t think this
variable is tidy, because the route data takes up multiple columns and
could be condensed into one column with additional rows.

``` r
# How many distinct stations?

distinct_stations <- nyc_df %>% 
  select(line, station_name) %>% 
  distinct() %>% 
  nrow()

# How many stations are ADA compliant? 

ada_compliant <- nyc_df %>% 
  select(line, station_name, ada) %>% 
  distinct() %>% 
  filter(ada == TRUE) %>% 
  nrow()

# What proportion of station entrances and exits without vending allow entrance?

no_vending <- nyc_df %>% 
  distinct() %>% 
  filter(vending == "NO") %>% 
  nrow()

allow_entry <- nyc_df %>%
  distinct() %>% 
  filter(vending == "NO",entry == TRUE) %>% 
  nrow()
```

There are 465 distinct stations, and 84 of these stations are ADA
compliant. 45/117 stations without vending allow entrance.

``` r
# Reformat so that route number and route name are distinct variables

nyc_df <- nyc_df %>% 
  mutate(route8 = as.character(route8), 
         route9 = as.character(route9), 
         route10 = as.character(route10), 
         route11 = as.character(route11)) %>% 
  pivot_longer(route1:route11, 
               names_to = "route_number", 
               values_to = "route_name") 
```

``` r
# Distinct stations that serve the A train? 

serve_a <- nyc_df %>% 
  filter(route_name == "A") %>% 
  select(line, station_name) %>% 
  distinct() %>%
  nrow()

# Of the stations that serve the A train, how many are ADA compliant?

ada_a <- nyc_df %>% 
  filter(route_name == "A") %>% 
  select(line, station_name, ada) %>% 
  distinct() %>% 
  filter(ada == TRUE) %>% 
  nrow()
```

There are 60 distinct stations that serve the A train. Of these
stations, 17 are ADA compliant.

## Problem 2

``` r
# Importing and cleaning Mr. Trash Wheel data

mr_wheel_df <- readxl::read_excel("Data/202409 Trash Wheel Collection Data.xlsx", 
                               sheet = "Mr. Trash Wheel", 
                               range = "A2:N653") %>% 
  janitor::clean_names() %>% 
  mutate(sports_balls = as.integer(round(sports_balls)), 
         wheel_name = "Mr. Trash Wheel", 
         year = as.double(year))


# Importing and cleaning Professor Trash Wheel data 

prof_wheel_df <- readxl::read_excel("Data/202409 Trash Wheel Collection Data.xlsx", 
                               sheet = "Professor Trash Wheel", 
                               range = "A2:M120") %>% 
  janitor::clean_names() %>% 
  mutate(wheel_name = "Professor Trash Wheel")


# Importing and cleaning Gwynnda data

gwn_df <- readxl::read_excel("Data/202409 Trash Wheel Collection Data.xlsx", 
                               sheet = "Gwynnda Trash Wheel", 
                               range = "A2:L265") %>% 
  janitor::clean_names() %>% 
  mutate(wheel_name = "Gwynnda")


# Combining all three wheels into one data set 

wheel_tidy <- bind_rows(mr_wheel_df, prof_wheel_df, gwn_df)
head(wheel_tidy)
```

    ## # A tibble: 6 × 15
    ##   dumpster month  year date                weight_tons volume_cubic_yards
    ##      <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ## 1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ## 2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ## 3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ## 4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ## 5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ## 6        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>, wheel_name <chr>

These data describe the amount and types of trash collected by three
different trash wheels (Mr. Trash Wheel, Professor Trash Wheel, and
Gwynnda) from 2014 to 2024. Each row represents a dumpster, which is
where a wheel deposits the trash it collects. This data set has 1,032
rows (observations) and 15 columns (variables). Some of the key
variables are the date of collection, trash weight (tons), trash volume
(cubic yards), and the number of homes powered.

``` r
# Calculating total weight of trash collected by Professor Trash Wheel

prof_sum <- prof_wheel_df %>% 
  select(weight_tons) %>% 
  sum()

# Calculating total number of cigarette butts collected by Gwynnda in June 2022

gwynnda_butts <- gwn_df %>% 
  filter(month == "June", year == 2022) %>% 
  select(cigarette_butts) %>% 
  sum()
```

The total weight of trash collected by Professor Trash Wheel was 246.74
tons. Gwynnda collected 18,120 cigarette butts in June of 2022.

## Problem 3

``` r
# Reading in and cleaning individual data sets 

bakers_df <- read_csv("Data/bakers.csv") %>% 
  janitor::clean_names()
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes_df <- read_csv("Data/bakes.csv") %>% 
  janitor::clean_names()
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
# Giving the columns names, removing irrelevant rows

results_df <- read_csv("Data/results.csv") 
```

    ## New names:
    ## Rows: 1138 Columns: 5
    ## ── Column specification
    ## ──────────────────────────────────────────────────────── Delimiter: "," chr
    ## (5): ...1, ...2, ...3, ...4, IN = stayed in; OUT = Eliminated; STAR BAKE...
    ## ℹ Use `spec()` to retrieve the full column specification for this data. ℹ
    ## Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## • `` -> `...1`
    ## • `` -> `...2`
    ## • `` -> `...3`
    ## • `` -> `...4`

``` r
names(results_df) <- c("series", "episode", "baker", "technical", "result")
results_df <- results_df %>% 
  filter(series != "series") %>% 
  mutate(series = as.double(series), 
         episode = as.double(episode))
```

``` r
# Joining tables 

results_bakes_df <- right_join(bakes_df, results_df, 
                              by = c("series" = "series", 
                                     "episode" = "episode", 
                                     "baker" = "baker"))

# Creating a first name column in bakers_df for merge

bakers_df <- bakers_df %>% 
  mutate(first_name = unlist(strsplit(baker_name, " "))[c(TRUE, FALSE)])


# Merging into full data set

full_df <- right_join(bakers_df, results_bakes_df, 
                      by = c("series" = "series", 
                             "first_name" = "baker"))

# Rearranging full data set

full_tidy_df <- full_df %>% 
  select(series, episode, baker_name, first_name, technical, result, 
         signature_bake, show_stopper, baker_age, baker_occupation, 
         hometown) %>% 
  arrange(series, baker_name, episode)

# Exporting as csv 

write_csv(full_tidy_df, "Data/full_tidy_df.csv")
```

I started my data cleaning process by reading in each table and using
clean_names() to fix the variable names. For the results data frame,
this was slightly more challenging because the columns didn’t have
names, and the real column names were registering as row entries, so I
had to assign names manually and then remove the first two rows.

To merge the data frames, I chose to preserve the length of results_df,
since it had data for the most series, episodes, and bakers. This does
mean that for my final data set, there are lots of rows that only
contain the series, episode, baker, and result data (no bake or baker
data). First, I merged bakes_df and results_df by comparing the series,
episode, and baker columns. To merge this with baker_df, I had to first
extract the first names out of the baker_name variable to create a new
column. Using this new column and the series column, I merged it with my
partially merged data set, results_bakes_df. Finally, I rearranged the
columns to make contestant performance easier to track and reordered the
rows by season, then baker, then episode.

The final data set has 11 columns and 1,136 rows, which represent
individual baker performance in each episode of a given season. Several
important variables are baker_name, series, episode, result, and
signature_bake.

``` r
winners_df <- full_tidy_df %>% 
  filter(series >= 5, 
         result %in% c("WINNER", "STAR BAKER")) %>% 
  arrange(series, episode)
```

This table has 60 rows and 11 columns. There were some surprise winners,
for example David in season 10 did not win “Star Baker” in any episode
until winning the full competition in episode 10. Similarly, Nancy in
season 1 only won “Star Baker” in the first episode, and then didn’t win
again until winning the final episode. There were some winners that were
predictable, such as Nadiya in season 6, Candice in season 7, and Sophie
in season 8, who all won “Star Baker” several times before winning the
season.

``` r
# Reading in and tidying viewers data

viewers_df <- read_csv("Data/viewers.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(series_1:series_10, 
               names_to = "series", 
               values_to = "viewers", 
               names_prefix = "series_") %>% 
  mutate(series = as.integer(series), 
         episode = as.integer(episode)) %>% 
  arrange(series, episode) %>% 
  select(series, episode, viewers)
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(viewers_df, 10)
```

    ## # A tibble: 10 × 3
    ##    series episode viewers
    ##     <int>   <int>   <dbl>
    ##  1      1       1    2.24
    ##  2      1       2    3   
    ##  3      1       3    3   
    ##  4      1       4    2.6 
    ##  5      1       5    3.03
    ##  6      1       6    2.75
    ##  7      1       7   NA   
    ##  8      1       8   NA   
    ##  9      1       9   NA   
    ## 10      1      10   NA

``` r
# Finding season 1 viewer average 

s1 <- viewers_df %>% 
  filter(series == 1) %>% 
  na.omit() %>% 
  select(viewers)

avg_s1 <- sum(s1)/6

# Finding season 5 viewer average

s5 <- viewers_df %>% 
  filter(series == 5) %>% 
  select(viewers)

avg_s5 <- sum(s5)/10
```

The average viewership in Season 1 was 2.77 million. The average
viewership in Season 5 was 10.04 million.
